{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc78074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51eb1b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website_url</th>\n",
       "      <th>cleaned_website_text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webpage_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.booking.com/index.html?aid=1743217</td>\n",
       "      <td>official site good hotel accommodation big sav...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://travelsites.com/expedia/</td>\n",
       "      <td>expedia hotel book sites like use vacation wor...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://travelsites.com/tripadvisor/</td>\n",
       "      <td>tripadvisor hotel book sites like previously d...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.momondo.in/?ispredir=true</td>\n",
       "      <td>cheap flights search compare flights momondo f...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ebookers.com/?AFFCID=EBOOKERS-UK.n...</td>\n",
       "      <td>bot create free account create free account si...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  website_url  \\\n",
       "webpage_id                                                      \n",
       "0              https://www.booking.com/index.html?aid=1743217   \n",
       "1                            https://travelsites.com/expedia/   \n",
       "2                        https://travelsites.com/tripadvisor/   \n",
       "3                       https://www.momondo.in/?ispredir=true   \n",
       "4           https://www.ebookers.com/?AFFCID=EBOOKERS-UK.n...   \n",
       "\n",
       "                                         cleaned_website_text Category  \n",
       "webpage_id                                                              \n",
       "0           official site good hotel accommodation big sav...   Travel  \n",
       "1           expedia hotel book sites like use vacation wor...   Travel  \n",
       "2           tripadvisor hotel book sites like previously d...   Travel  \n",
       "3           cheap flights search compare flights momondo f...   Travel  \n",
       "4           bot create free account create free account si...   Travel  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"website_classification.csv\", index_col='webpage_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb26a933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/harshasaijagu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/harshasaijagu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  website_url  \\\n",
      "webpage_id                                                      \n",
      "0              https://www.booking.com/index.html?aid=1743217   \n",
      "1                            https://travelsites.com/expedia/   \n",
      "2                        https://travelsites.com/tripadvisor/   \n",
      "3                       https://www.momondo.in/?ispredir=true   \n",
      "4           https://www.ebookers.com/?AFFCID=EBOOKERS-UK.n...   \n",
      "\n",
      "                                         cleaned_website_text  Category  \\\n",
      "webpage_id                                                                \n",
      "0           official site good hotel accommodation big sav...        15   \n",
      "1           expedia hotel book sites like use vacation wor...        15   \n",
      "2           tripadvisor hotel book sites like previously d...        15   \n",
      "3           cheap flights search compare flights momondo f...        15   \n",
      "4           bot create free account create free account si...        15   \n",
      "\n",
      "                                              cleaned_content  \n",
      "webpage_id                                                     \n",
      "0           official site good hotel accommodation big sav...  \n",
      "1           expedia hotel book sites like use vacation wor...  \n",
      "2           tripadvisor hotel book sites like previously d...  \n",
      "3           cheap flights search compare flights momondo f...  \n",
      "4           bot create free account create free account si...  \n"
     ]
    }
   ],
   "source": [
    "# Preprocess text data\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Join the tokens back into a single string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['Category'] = label_encoder.fit_transform(df['Category'])\n",
    "\n",
    "# Apply preprocessing to the 'content' column\n",
    "df['cleaned_content'] = df['cleaned_website_text'].apply(preprocess_text)\n",
    "\n",
    "# Display the first few rows of the preprocessed DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5fd1305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1126,) (1126,)\n",
      "Testing set shape: (282,) (282,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_content'], df['Category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae11022",
   "metadata": {},
   "source": [
    "### TF - IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b10454f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF vectors (training): (1126, 500)\n",
      "Shape of TF-IDF vectors (testing): (282, 500)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=500)  # You can adjust max_features based on your dataset size\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Display the shape of the TF-IDF vectors\n",
    "print(\"Shape of TF-IDF vectors (training):\", X_train_tfidf.shape)\n",
    "print(\"Shape of TF-IDF vectors (testing):\", X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d730b",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b82a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_embeddings(tokens, model, vector_size):\n",
    "    valid_tokens = [token for token in tokens if token in model.wv.key_to_index]\n",
    "    if valid_tokens:\n",
    "        avg_embedding = np.mean([model.wv[token] for token in valid_tokens], axis=0)\n",
    "    else:\n",
    "        avg_embedding = np.zeros(vector_size)\n",
    "    return avg_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8544427a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of word embeddings matrix (training): (1126, 100)\n",
      "Shape of word embeddings matrix (testing): (282, 100)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text data for training and testing sets\n",
    "tokenized_text_train = [word_tokenize(text) for text in X_train]\n",
    "tokenized_text_test = [word_tokenize(text) for text in X_test]\n",
    "\n",
    "# Train Word2Vec model on the training set\n",
    "word2vec_model = Word2Vec(sentences=tokenized_text_train, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Generate word embeddings for each document in the training set\n",
    "word_embeddings_train = np.vstack([average_word_embeddings(tokens, word2vec_model, 100) for tokens in tokenized_text_train])\n",
    "\n",
    "# Generate word embeddings for each document in the testing set\n",
    "word_embeddings_test = np.vstack([average_word_embeddings(tokens, word2vec_model, 100) for tokens in tokenized_text_test])\n",
    "\n",
    "# Display the shape of the word embeddings matrices for training and testing sets\n",
    "print(\"Shape of word embeddings matrix (training):\", word_embeddings_train.shape)\n",
    "print(\"Shape of word embeddings matrix (testing):\", word_embeddings_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a45d2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate word embeddings and TF-IDF vectors for training and testing sets\n",
    "X_train_features = np.concatenate([word_embeddings_train, X_train_tfidf.toarray()], axis=1)\n",
    "X_test_features = np.concatenate([word_embeddings_test, X_test_tfidf.toarray()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4484b3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.54      0.76      0.63        17\n",
      "           2       0.65      0.68      0.67        19\n",
      "           3       0.88      1.00      0.94        22\n",
      "           4       0.85      0.81      0.83        27\n",
      "           5       0.94      0.88      0.91        17\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.95      0.82      0.88        22\n",
      "           8       0.92      0.92      0.92        13\n",
      "           9       0.95      0.91      0.93        23\n",
      "          10       0.84      0.89      0.86        18\n",
      "          11       0.94      0.85      0.89        20\n",
      "          12       0.87      0.72      0.79        18\n",
      "          13       0.92      0.96      0.94        23\n",
      "          14       1.00      1.00      1.00        18\n",
      "          15       1.00      0.95      0.97        19\n",
      "\n",
      "    accuracy                           0.86       282\n",
      "   macro avg       0.83      0.81      0.81       282\n",
      "weighted avg       0.87      0.86      0.86       282\n",
      "\n",
      "Accuracy Score: 0.8617021276595744\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the classifier on the combined features\n",
    "svm_classifier.fit(X_train_features, y_train)\n",
    "\n",
    "# Predict the categories for the testing data\n",
    "y_pred = svm_classifier.predict(X_test_features)\n",
    "\n",
    "# Display the classification report and accuracy score\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "035222bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       0.65      0.76      0.70        17\n",
      "           2       0.73      0.84      0.78        19\n",
      "           3       0.95      0.86      0.90        22\n",
      "           4       0.85      0.85      0.85        27\n",
      "           5       0.89      0.94      0.91        17\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.95      0.86      0.90        22\n",
      "           8       0.92      0.85      0.88        13\n",
      "           9       0.80      0.87      0.83        23\n",
      "          10       0.75      0.83      0.79        18\n",
      "          11       0.94      0.85      0.89        20\n",
      "          12       0.94      0.89      0.91        18\n",
      "          13       0.95      0.87      0.91        23\n",
      "          14       0.90      1.00      0.95        18\n",
      "          15       0.95      0.95      0.95        19\n",
      "\n",
      "    accuracy                           0.86       282\n",
      "   macro avg       0.82      0.80      0.80       282\n",
      "weighted avg       0.87      0.86      0.86       282\n",
      "\n",
      "Accuracy Score: 0.8617021276595744\n"
     ]
    }
   ],
   "source": [
    "xgboost = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Train the classifier on the combined features\n",
    "xgboost.fit(X_train_features, y_train)\n",
    "\n",
    "# Predict the categories for the testing data\n",
    "y_pred = xgboost.predict(X_test_features)\n",
    "\n",
    "# Display the classification report and accuracy score\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a4e3b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshasaijagu/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 0s - 15ms/step - accuracy: 0.1133 - loss: 2.7275 - val_accuracy: 0.1991 - val_loss: 2.6186\n",
      "Epoch 2/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.1889 - loss: 2.5051 - val_accuracy: 0.5088 - val_loss: 2.1979\n",
      "Epoch 3/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.3311 - loss: 2.0884 - val_accuracy: 0.5885 - val_loss: 1.6570\n",
      "Epoch 4/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.4922 - loss: 1.6572 - val_accuracy: 0.7080 - val_loss: 1.2653\n",
      "Epoch 5/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.5878 - loss: 1.3004 - val_accuracy: 0.8186 - val_loss: 0.9196\n",
      "Epoch 6/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.6444 - loss: 1.1540 - val_accuracy: 0.8186 - val_loss: 0.8206\n",
      "Epoch 7/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.7167 - loss: 0.9316 - val_accuracy: 0.8230 - val_loss: 0.7229\n",
      "Epoch 8/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.7500 - loss: 0.8776 - val_accuracy: 0.8451 - val_loss: 0.6690\n",
      "Epoch 9/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.7900 - loss: 0.7029 - val_accuracy: 0.8496 - val_loss: 0.6273\n",
      "Epoch 10/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.8022 - loss: 0.6446 - val_accuracy: 0.8584 - val_loss: 0.5685\n",
      "Epoch 11/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.8467 - loss: 0.5197 - val_accuracy: 0.8540 - val_loss: 0.5810\n",
      "Epoch 12/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.8578 - loss: 0.4862 - val_accuracy: 0.8805 - val_loss: 0.5235\n",
      "Epoch 13/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.8756 - loss: 0.4182 - val_accuracy: 0.8628 - val_loss: 0.5440\n",
      "Epoch 14/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.8767 - loss: 0.4206 - val_accuracy: 0.8628 - val_loss: 0.5393\n",
      "Epoch 15/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.8944 - loss: 0.3717 - val_accuracy: 0.8628 - val_loss: 0.5690\n",
      "Epoch 16/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.8944 - loss: 0.3705 - val_accuracy: 0.8761 - val_loss: 0.5781\n",
      "Epoch 17/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.9122 - loss: 0.3091 - val_accuracy: 0.8717 - val_loss: 0.5716\n",
      "Epoch 18/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.9278 - loss: 0.2612 - val_accuracy: 0.8761 - val_loss: 0.5959\n",
      "Epoch 19/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.9311 - loss: 0.2435 - val_accuracy: 0.8805 - val_loss: 0.5440\n",
      "Epoch 20/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.9289 - loss: 0.2289 - val_accuracy: 0.8584 - val_loss: 0.6098\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.63      0.71      0.67        17\n",
      "           2       0.68      0.89      0.77        19\n",
      "           3       0.88      0.95      0.91        22\n",
      "           4       0.88      0.85      0.87        27\n",
      "           5       0.88      0.88      0.88        17\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.95      0.82      0.88        22\n",
      "           8       0.90      0.69      0.78        13\n",
      "           9       0.85      0.96      0.90        23\n",
      "          10       0.89      0.89      0.89        18\n",
      "          11       0.94      0.85      0.89        20\n",
      "          12       0.86      0.67      0.75        18\n",
      "          13       0.92      0.96      0.94        23\n",
      "          14       0.86      1.00      0.92        18\n",
      "          15       1.00      0.95      0.97        19\n",
      "\n",
      "    accuracy                           0.86       282\n",
      "   macro avg       0.82      0.80      0.81       282\n",
      "weighted avg       0.86      0.86      0.86       282\n",
      "\n",
      "Accuracy Score: 0.8617021276595744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshasaijagu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harshasaijagu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harshasaijagu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert the labels to one-hot encoding for neural network\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "# Define the neural network model\n",
    "def create_neural_network(input_dim, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "input_dim = X_train_features.shape[1]\n",
    "num_classes = len(label_encoder.classes_)\n",
    "neural_network = create_neural_network(input_dim, num_classes)\n",
    "\n",
    "# Train the neural network model\n",
    "neural_network.fit(X_train_features, y_train_categorical, epochs=20, batch_size=32, validation_split=0.2, verbose=2)\n",
    "\n",
    "# Predict the categories for the testing data\n",
    "y_pred_categorical = neural_network.predict(X_test_features)\n",
    "y_pred = np.argmax(y_pred_categorical, axis=1)\n",
    "\n",
    "# Display the classification report and accuracy score\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd93fd3",
   "metadata": {},
   "source": [
    "### Topic Modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b22b4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of LDA topic distributions (training): (1126, 16)\n",
      "Shape of LDA topic distributions (testing): (282, 16)\n",
      "Shape of combined features (training): (1126, 616)\n",
      "Shape of combined features (testing): (282, 616)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Define the number of topics\n",
    "num_topics = 16\n",
    "\n",
    "# Perform LDA on the TF-IDF vectors of the training set\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda_train = lda_model.fit_transform(X_train_tfidf)\n",
    "lda_test = lda_model.transform(X_test_tfidf)\n",
    "\n",
    "# Display the shape of the LDA topic distributions\n",
    "print(\"Shape of LDA topic distributions (training):\", lda_train.shape)\n",
    "print(\"Shape of LDA topic distributions (testing):\", lda_test.shape)\n",
    "\n",
    "# Combine word embeddings, TF-IDF vectors, and LDA topic distributions for training and testing sets\n",
    "X_train_features = np.concatenate([word_embeddings_train, X_train_tfidf.toarray(), lda_train], axis=1)\n",
    "X_test_features = np.concatenate([word_embeddings_test, X_test_tfidf.toarray(), lda_test], axis=1)\n",
    "\n",
    "# Display the shape of the final feature matrices\n",
    "print(\"Shape of combined features (training):\", X_train_features.shape)\n",
    "print(\"Shape of combined features (testing):\", X_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b19823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.57      0.76      0.65        17\n",
      "           2       0.73      0.84      0.78        19\n",
      "           3       0.88      1.00      0.94        22\n",
      "           4       0.88      0.81      0.85        27\n",
      "           5       0.94      0.88      0.91        17\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.90      0.82      0.86        22\n",
      "           8       0.92      0.92      0.92        13\n",
      "           9       0.95      0.91      0.93        23\n",
      "          10       0.89      0.89      0.89        18\n",
      "          11       0.95      0.90      0.92        20\n",
      "          12       0.87      0.72      0.79        18\n",
      "          13       0.92      0.96      0.94        23\n",
      "          14       1.00      1.00      1.00        18\n",
      "          15       1.00      0.95      0.97        19\n",
      "\n",
      "    accuracy                           0.88       282\n",
      "   macro avg       0.84      0.82      0.83       282\n",
      "weighted avg       0.88      0.88      0.88       282\n",
      "\n",
      "Accuracy Score: 0.875886524822695\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC(kernel='linear', random_state=42, probability=True)\n",
    "\n",
    "# Train the classifier on the combined features\n",
    "svm_classifier.fit(X_train_features, y_train)\n",
    "\n",
    "# Predict the categories for the testing data\n",
    "y_pred = svm_classifier.predict(X_test_features)\n",
    "\n",
    "# Display the classification report and accuracy score\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "251d30c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.67      0.82      0.74        17\n",
      "           2       0.65      0.79      0.71        19\n",
      "           3       0.91      0.95      0.93        22\n",
      "           4       0.80      0.74      0.77        27\n",
      "           5       0.88      0.88      0.88        17\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.95      0.86      0.90        22\n",
      "           8       0.91      0.77      0.83        13\n",
      "           9       0.88      0.91      0.89        23\n",
      "          10       0.81      0.94      0.87        18\n",
      "          11       1.00      0.85      0.92        20\n",
      "          12       0.92      0.67      0.77        18\n",
      "          13       0.91      0.91      0.91        23\n",
      "          14       0.86      1.00      0.92        18\n",
      "          15       0.90      0.95      0.92        19\n",
      "\n",
      "    accuracy                           0.85       282\n",
      "   macro avg       0.82      0.80      0.80       282\n",
      "weighted avg       0.86      0.85      0.85       282\n",
      "\n",
      "Random Forest Accuracy Score: 0.8546099290780141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshasaijagu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harshasaijagu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harshasaijagu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train_features, y_train)\n",
    "y_pred_rf = random_forest.predict(X_test_features)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Random Forest Accuracy Score:\", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3087a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.76      0.84      0.80        19\n",
      "           3       0.95      0.82      0.88        22\n",
      "           4       0.83      0.89      0.86        27\n",
      "           5       0.89      0.94      0.91        17\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.95      0.86      0.90        22\n",
      "           8       0.85      0.85      0.85        13\n",
      "           9       0.91      0.87      0.89        23\n",
      "          10       0.67      0.89      0.76        18\n",
      "          11       1.00      0.85      0.92        20\n",
      "          12       0.88      0.83      0.86        18\n",
      "          13       0.91      0.87      0.89        23\n",
      "          14       0.89      0.94      0.92        18\n",
      "          15       0.86      0.95      0.90        19\n",
      "\n",
      "    accuracy                           0.85       282\n",
      "   macro avg       0.82      0.79      0.79       282\n",
      "weighted avg       0.86      0.85      0.85       282\n",
      "\n",
      "Accuracy Score: 0.8546099290780141\n"
     ]
    }
   ],
   "source": [
    "xgboost = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Train the classifier on the combined features\n",
    "xgboost.fit(X_train_features, y_train)\n",
    "\n",
    "# Predict the categories for the testing data\n",
    "y_pred = xgboost.predict(X_test_features)\n",
    "\n",
    "# Display the classification report and accuracy score\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf1c8b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshasaijagu/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 0s - 16ms/step - accuracy: 0.0967 - loss: 2.7254 - val_accuracy: 0.2566 - val_loss: 2.5412\n",
      "Epoch 2/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.2289 - loss: 2.4045 - val_accuracy: 0.5575 - val_loss: 2.0786\n",
      "Epoch 3/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.3311 - loss: 2.0259 - val_accuracy: 0.6770 - val_loss: 1.6078\n",
      "Epoch 4/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.4722 - loss: 1.6382 - val_accuracy: 0.8097 - val_loss: 1.1556\n",
      "Epoch 5/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.5944 - loss: 1.3072 - val_accuracy: 0.8142 - val_loss: 0.9173\n",
      "Epoch 6/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.6722 - loss: 1.0678 - val_accuracy: 0.8274 - val_loss: 0.7807\n",
      "Epoch 7/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.7311 - loss: 0.9448 - val_accuracy: 0.8363 - val_loss: 0.7329\n",
      "Epoch 8/20\n",
      "29/29 - 0s - 3ms/step - accuracy: 0.7578 - loss: 0.8183 - val_accuracy: 0.8451 - val_loss: 0.6533\n",
      "Epoch 9/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.7933 - loss: 0.6586 - val_accuracy: 0.8363 - val_loss: 0.6141\n",
      "Epoch 10/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.8344 - loss: 0.5729 - val_accuracy: 0.8451 - val_loss: 0.5944\n",
      "Epoch 11/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.8400 - loss: 0.5599 - val_accuracy: 0.8496 - val_loss: 0.5681\n",
      "Epoch 12/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.8667 - loss: 0.4360 - val_accuracy: 0.8451 - val_loss: 0.5938\n",
      "Epoch 13/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.8844 - loss: 0.4033 - val_accuracy: 0.8584 - val_loss: 0.5756\n",
      "Epoch 14/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.8878 - loss: 0.3858 - val_accuracy: 0.8451 - val_loss: 0.5794\n",
      "Epoch 15/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.8933 - loss: 0.3458 - val_accuracy: 0.8717 - val_loss: 0.5740\n",
      "Epoch 16/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.8989 - loss: 0.3078 - val_accuracy: 0.8673 - val_loss: 0.6131\n",
      "Epoch 17/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.9111 - loss: 0.2958 - val_accuracy: 0.8584 - val_loss: 0.5990\n",
      "Epoch 18/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.9189 - loss: 0.2601 - val_accuracy: 0.8496 - val_loss: 0.6288\n",
      "Epoch 19/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.9378 - loss: 0.2347 - val_accuracy: 0.8540 - val_loss: 0.5871\n",
      "Epoch 20/20\n",
      "29/29 - 0s - 2ms/step - accuracy: 0.9422 - loss: 0.2129 - val_accuracy: 0.8496 - val_loss: 0.6783\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       0.83      0.59      0.69        17\n",
      "           2       0.63      0.89      0.74        19\n",
      "           3       0.81      0.95      0.88        22\n",
      "           4       0.77      0.89      0.83        27\n",
      "           5       0.88      0.82      0.85        17\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.94      0.77      0.85        22\n",
      "           8       0.86      0.92      0.89        13\n",
      "           9       0.86      0.83      0.84        23\n",
      "          10       0.84      0.89      0.86        18\n",
      "          11       0.94      0.80      0.86        20\n",
      "          12       0.86      0.67      0.75        18\n",
      "          13       0.92      0.96      0.94        23\n",
      "          14       0.86      1.00      0.92        18\n",
      "          15       0.95      0.95      0.95        19\n",
      "\n",
      "    accuracy                           0.84       282\n",
      "   macro avg       0.81      0.78      0.78       282\n",
      "weighted avg       0.85      0.84      0.84       282\n",
      "\n",
      "Accuracy Score: 0.8439716312056738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshasaijagu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harshasaijagu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harshasaijagu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert the labels to one-hot encoding for neural network\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "# Define the neural network model\n",
    "def create_neural_network(input_dim, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "input_dim = X_train_features.shape[1]\n",
    "num_classes = len(label_encoder.classes_)\n",
    "neural_network = create_neural_network(input_dim, num_classes)\n",
    "\n",
    "# Train the neural network model\n",
    "neural_network.fit(X_train_features, y_train_categorical, epochs=20, batch_size=32, validation_split=0.2, verbose=2)\n",
    "\n",
    "# Predict the categories for the testing data\n",
    "y_pred_categorical = neural_network.predict(X_test_features)\n",
    "y_pred = np.argmax(y_pred_categorical, axis=1)\n",
    "\n",
    "# Display the classification report and accuracy score\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6b008f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.64      0.82      0.72        17\n",
      "           2       0.74      0.89      0.81        19\n",
      "           3       0.91      0.95      0.93        22\n",
      "           4       0.92      0.85      0.88        27\n",
      "           5       0.89      0.94      0.91        17\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.95      0.82      0.88        22\n",
      "           8       0.92      0.92      0.92        13\n",
      "           9       0.95      0.87      0.91        23\n",
      "          10       0.73      0.89      0.80        18\n",
      "          11       1.00      0.85      0.92        20\n",
      "          12       0.93      0.78      0.85        18\n",
      "          13       0.91      0.91      0.91        23\n",
      "          14       1.00      1.00      1.00        18\n",
      "          15       0.95      0.95      0.95        19\n",
      "\n",
      "    accuracy                           0.88       282\n",
      "   macro avg       0.84      0.83      0.83       282\n",
      "weighted avg       0.89      0.88      0.88       282\n",
      "\n",
      "Voting Classifier Accuracy Score: 0.8794326241134752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('svm', svm_classifier),\n",
    "    ('rf', random_forest),\n",
    "    ('xgb', xgboost)\n",
    "], voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train_features, y_train)\n",
    "y_pred_voting = voting_clf.predict(X_test_features)\n",
    "\n",
    "print(\"Voting Classifier Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_voting))\n",
    "print(\"Voting Classifier Accuracy Score:\", accuracy_score(y_test, y_pred_voting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b7936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
